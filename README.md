# ✋ Gesture-Controlled Virtual Keyboard  

A real-time **gesture-based virtual keyboard** that allows users to perform search queries on **Google, YouTube, and Instagram** using only their hands—no physical input devices required.  

This project uses **computer vision** and **hand tracking** to detect fingertip positions and recognize tap gestures, enabling text input through an on-screen keyboard. Once a query is typed, the system automatically launches a search in the browser.  

---

## 🚀 Features  
- **Real-Time Gesture Input** – Detects fingertip taps using MediaPipe hand landmarks.  
- **Virtual Keyboard** – Dynamic, color-coded keyboard fully rendered with OpenCV.  
- **Multi-Platform Support** – Perform searches on Google, YouTube, and Instagram.  
- **Auto Search Execution** – Automatically launches search after a short pause.  
- **Visual Feedback** – Displays typed text, gesture detection, and active platform.  

---

## 🛠️ Tech Stack  
- **Python** – Core language for logic and flow.  
- **OpenCV** – Real-time video capture, rendering, and image processing.  
- **MediaPipe** – Hand tracking and landmark detection.  
- **NumPy** – Numerical operations (e.g., distance calculations).  
- **webbrowser module** – Launches search queries directly in the browser.  

---

## 🎯 Real-World Use Cases  
- **Assistive Technology** – Helps users with mobility impairments interact without keyboards or mice.  
- **Public Interfaces** – Safer touchless input for kiosks and smart displays.  
- **Creative Applications** – Interactive installations, education tools, and futuristic UX designs.  

---

## 🔮 Future Improvements  
- Gesture-based scrolling & navigation for search results.  
- Custom gesture training with ML models.  
- Multilingual keyboard support.  
- Chrome extension integration for direct browser control.  

---

## 🙏 Acknowledgments  
Special thanks to **Muhammad Usama** for mentorship and guidance throughout this project.  

---
